{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Mini Project",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8HxBDUhFSLa",
        "outputId": "e473dc0b-1fef-49d2-b9d9-fcc1914da0d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "# setting up the data path\n",
        "import os \n",
        "# Importing all the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "\n",
        "# Importing Train and Test datasets\n",
        "train_data = pd.read_csv(\"fashion-mnist_train.csv\")\n",
        "final_test_data = pd.read_csv(\"fashion-mnist_test.csv\")\n",
        "\n",
        "\n",
        "# Splitting independent variables from the dependent variable in both training and testing\n",
        "X_train = train_data.iloc[:,1:]\n",
        "y_train = train_data.label.astype(\"str\")\n",
        "\n",
        "X_final_test = final_test_data.iloc[:,1:]\n",
        "y_final_test = final_test_data.label.astype(\"str\")\n",
        "\n",
        "\n",
        "\n",
        "# Splitting train data into training and validation datasets\n",
        "x_train, x_test, y_train_v, y_test_v = train_test_split(X_train,y_train, test_size = 0.3, random_state = 2)\n",
        "\n",
        "# ================== Using Random Forest without hyper paramter tuning and clustering ===================\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(x_train,y_train_v)\n",
        "# Predictions on training and validation\n",
        "y_pred_train = rf.predict(x_train)\n",
        "    # predictions for test\n",
        "y_pred_test = rf.predict(x_test)\n",
        "    # training metrics\n",
        "print(\"Training metrics:\")\n",
        "print(sklearn.metrics.classification_report(y_true= y_train_v, y_pred= y_pred_train))\n",
        "    \n",
        "    # test data metrics\n",
        "print(\"Test data metrics:\")\n",
        "print(sklearn.metrics.classification_report(y_true= y_test_v, y_pred= y_pred_test))\n",
        "\n",
        "\n",
        "# Predictions on testset\n",
        "y_pred_test = rf.predict(X_final_test)\n",
        "    # test data metrics\n",
        "print(\"Test data metrics:\")\n",
        "print(sklearn.metrics.classification_report(y_true= y_final_test, y_pred= y_pred_test))\n",
        "\n",
        "# Results:\n",
        "#    86% accuracy on both validation and test datasets\n",
        "\n",
        "\n",
        "# =========================== Using Grid Search for hyper parameter tuning ===================================\n",
        "clf = GridSearchCV(rf, param_grid={'n_estimators':[100,200],'min_samples_leaf':[2,3]})\n",
        "model = clf.fit(x_train,y_train_v)\n",
        "\n",
        "\n",
        "y_pred_train = model.predict(x_train)\n",
        "    # predictions for test\n",
        "y_pred_test = model.predict(x_test)\n",
        "    # training metrics\n",
        "print(\"Training metrics:\")\n",
        "print(sklearn.metrics.classification_report(y_true= y_train_v, y_pred= y_pred_train))\n",
        "    \n",
        "    # test data metrics\n",
        "print(\"Test data metrics:\")\n",
        "print(sklearn.metrics.classification_report(y_true= y_test_v, y_pred= y_pred_test))\n",
        "\n",
        "\n",
        "# Predictions on testset\n",
        "y_pred_test = model.predict(X_final_test)\n",
        "    # test data metrics\n",
        "print(\"Test data metrics:\")\n",
        "print(sklearn.metrics.classification_report(y_true= y_final_test, y_pred= y_pred_test))\n",
        "print(sklearn.metrics.classification_matrix(y_true= y_final_test, y_pred= y_pred_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      4163\n",
            "           1       1.00      1.00      1.00      4211\n",
            "           2       1.00      1.00      1.00      4211\n",
            "           3       1.00      1.00      1.00      4182\n",
            "           4       1.00      1.00      1.00      4243\n",
            "           5       1.00      1.00      1.00      4203\n",
            "           6       1.00      1.00      1.00      4214\n",
            "           7       1.00      1.00      1.00      4135\n",
            "           8       1.00      1.00      1.00      4222\n",
            "           9       1.00      1.00      1.00      4216\n",
            "\n",
            "    accuracy                           1.00     42000\n",
            "   macro avg       1.00      1.00      1.00     42000\n",
            "weighted avg       1.00      1.00      1.00     42000\n",
            "\n",
            "Test data metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.87      0.84      1837\n",
            "           1       1.00      0.96      0.98      1789\n",
            "           2       0.80      0.82      0.81      1789\n",
            "           3       0.87      0.92      0.89      1818\n",
            "           4       0.77      0.84      0.80      1757\n",
            "           5       0.97      0.96      0.96      1797\n",
            "           6       0.74      0.59      0.66      1786\n",
            "           7       0.94      0.94      0.94      1865\n",
            "           8       0.96      0.97      0.96      1778\n",
            "           9       0.95      0.96      0.95      1784\n",
            "\n",
            "    accuracy                           0.88     18000\n",
            "   macro avg       0.88      0.88      0.88     18000\n",
            "weighted avg       0.88      0.88      0.88     18000\n",
            "\n",
            "Test data metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.86      0.83      1000\n",
            "           1       0.99      0.97      0.98      1000\n",
            "           2       0.79      0.80      0.79      1000\n",
            "           3       0.89      0.92      0.90      1000\n",
            "           4       0.80      0.86      0.83      1000\n",
            "           5       0.97      0.95      0.96      1000\n",
            "           6       0.74      0.59      0.66      1000\n",
            "           7       0.92      0.92      0.92      1000\n",
            "           8       0.95      0.97      0.96      1000\n",
            "           9       0.93      0.95      0.94      1000\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}